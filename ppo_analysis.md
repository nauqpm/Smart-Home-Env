# üìä Ph√¢n T√≠ch Chi Ti·∫øt: T·∫°i Sao PPO Th·∫Øng Hybrid

## üéØ T√≥m T·∫Øt K·∫øt Qu·∫£

| Metric | PPO Agent | Hybrid Agent | Ch√™nh l·ªách |
|--------|-----------|--------------|------------|
| **Total Bill** | **-87.5K VND** | 92.4K VND | ~180K VND |
| **Comfort Score** | **96/100** | 59-76/100 | +20-37 ƒëi·ªÉm |
| **K·∫øt lu·∫≠n** | ‚úÖ **WINS** | ‚ùå | |

---

## üß† Ki·∫øn Tr√∫c 2 Agent

### 1. Pure PPO Agent (`ppo_smart_home.zip`)

```mermaid
graph LR
    A[Observation 13D] --> B[MLP Policy]
    B --> C[Action 7D]
    C --> D[Environment]
    D --> E[Reward]
    E --> B
```

- **Training**: 10,000 episodes √ó 24 steps = 240,000 timesteps
- **Action Space**: 7 chi·ªÅu li√™n t·ª•c [-1, 1]
  - `[0]` Battery charge/discharge
  - `[1-3]` AC Living, Master, Bed2
  - `[4]` EV charger
  - `[5]` Washing Machine
  - `[6]` Dishwasher

### 2. Hybrid Agent (`ppo_hybrid_smart_home.zip`)

```mermaid
graph LR
    A[Observation] --> B[PPO Model]
    B --> C[Raw Action]
    C --> D{Rule-Based Override}
    D --> E[Modified Action]
    E --> F[Environment]
```

**Rule-Based Overrides trong `HybridAgentWrapper.predict()`:**

```python
# Rule 1: EV off-peak charging (22:00 - 04:00)
if (hour >= 22 or hour < 4) and ev_soc < 0.9:
    a[4] = 1.0  # Force max charging

# Rule 2: EV deadline enforcement
if need > 0 and need > pmax * hours_left * 0.8:
    a[4] = 1.0  # Force charging when urgent

# Rule 3: Battery safety
if soc < 0.15:
    a[0] = max(0.0, a[0])  # Prevent discharge

# Rule 4: AC off when no one home
if n_home == 0:
    a[1:4] = -1.0  # Turn off all ACs
else:
    for room in ["living", "master", "bed2"]:
        if not occupied(room, hour):
            a[idx] = min(a[idx], -0.3)  # Limit AC
```

---

## ‚ö° Reward Function Analysis

### C√¥ng th·ª©c Reward (t·ª´ `smart_home_env.py:284-289`)

```python
reward = -step_cost / 2000.0 - comfort_penalty

# EV shaping bonus/penalty
ev_deficit = max(0.0, 0.9 - ev_soc)
reward -= ev_deficit * (5.0 / hours_left)
```

### C√°c Th√†nh Ph·∫ßn Reward:

| Component | Formula | Weight |
|-----------|---------|--------|
| **Cost** | `-step_cost / 2000` | Ch√≠nh |
| **Comfort** | `-(temp - 25)¬≤ if occupied` | Ph·∫°t khi n√≥ng/l·∫°nh |
| **EV Deadline** | `-deficit √ó (5/hours_left)` | TƒÉng d·∫ßn khi g·∫ßn deadline |
| **End Penalties** | WM: -20, DW: -15, EV: -30 | Ph·∫°t n·∫∑ng n·∫øu ch∆∞a xong |

### Tiered Electricity Pricing (Vietnam):

```python
tiers = [
    (50 kWh, 1,984 VND/kWh),   # B·∫≠c 1
    (50 kWh, 2,050 VND/kWh),   # B·∫≠c 2
    (100 kWh, 2,380 VND/kWh),  # B·∫≠c 3
    (100 kWh, 2,998 VND/kWh),  # B·∫≠c 4
    (100 kWh, 3,350 VND/kWh),  # B·∫≠c 5
    (‚àû, 3,460 VND/kWh)         # B·∫≠c 6
]
```

**Export Revenue**: 2,000 VND/kWh (b√°n ƒëi·ªán v·ªÅ l∆∞·ªõi)

---

## üîç L√Ω Do PPO Th·∫Øng Hybrid

### 1. **Rule-Based Kh√¥ng T·ªëi ∆Øu Chi Ph√≠**

> [!CAUTION]
> Hybrid b·∫Øt bu·ªôc s·∫°c EV 100% v√†o gi·ªù off-peak (22:00-04:00), **NH∆ØNG** gi√° ƒëi·ªán l√∫c n√†y kh√¥ng ph·∫£i th·∫•p nh·∫•t trong m√¥ h√¨nh hi·ªán t·∫°i!

```python
# Gi√° ƒëi·ªán hi·ªán t·∫°i (t·ª´ main.py)
PRICE_PROFILE = [0.1]*6 + [0.15]*6 + [0.25]*6 + [0.18]*6
#                ^^^^^    ^^^^^^^    ^^^^^^^    ^^^^^^^
#               0-5h     6-11h      12-17h     18-23h
#               TH·∫§P     TRUNG      CAO        TRUNG
```

**PPO h·ªçc ƒë∆∞·ª£c**: S·∫°c EV v√†o 0-5h (gi√° th·∫•p nh·∫•t), kh√¥ng c·∫ßn s·∫°c l√∫c 22-23h (gi√° trung b√¨nh).

### 2. **AC Overriding G√¢y Comfort Penalty**

```python
# Hybrid rule: T·∫Øt AC khi kh√¥ng ·ªü nh√†
if n_home == 0:
    a[1:4] = -1.0
```

> [!WARNING]
> Khi ng∆∞·ªùi v·ªÅ nh√† (18:00), ph√≤ng ƒë√£ n√≥ng (do AC t·∫Øt c·∫£ ng√†y). PPO c·∫ßn b·∫≠t AC m·∫°nh ƒë·ªÉ l√†m m√°t ‚Üí **comfort penalty cao h∆°n mong ƒë·ª£i**.

**PPO h·ªçc ƒë∆∞·ª£c**: Pre-cool ph√≤ng tr∆∞·ªõc khi ng∆∞·ªùi v·ªÅ, gi·ªØ nhi·ªát ƒë·ªô ·ªïn ƒë·ªãnh h∆°n.

### 3. **Battery Strategy Conflict**

```python
# Hybrid rule: Kh√¥ng cho x·∫£ pin khi SOC < 15%
if soc < 0.15:
    a[0] = max(0.0, a[0])
```

**PPO**: H·ªçc ƒë∆∞·ª£c c√°ch qu·∫£n l√Ω pin linh ho·∫°t h∆°n:
- X·∫£ pin l√∫c 12-17h (gi√° cao) ƒë·ªÉ gi·∫£m grid import
- S·∫°c l√∫c 0-5h (gi√° th·∫•p) + PV ban ng√†y
- T·∫°o ƒë∆∞·ª£c **negative bill** (b√°n ƒëi·ªán d∆∞ v·ªÅ l∆∞·ªõi)

### 4. **End-to-End Optimization vs Local Rules**

```mermaid
graph TD
    subgraph "PPO (Global Optimization)"
        A[State] --> B[Neural Network]
        B --> C[Optimal Action]
        C --> D[Maximize Total Reward]
    end
    
    subgraph "Hybrid (Local Rules)"
        E[State] --> F[Neural Network]
        F --> G[Action]
        G --> H{Rule Check}
        H -->|Override| I[Modified Action]
        I --> J[Suboptimal Reward]
    end
```

---

## üìà Bi·ªÉu ƒê·ªì So S√°nh

### Screenshots t·ª´ Simulation:

````carousel
![PPO vs Hybrid Dashboard - Initial comparison showing PPO with lower bill](C:/Users/quanp/.gemini/antigravity/brain/c6041e0b-5d1e-4f60-abf9-0983a187a48b/ppo_vs_hybrid_dashboard_1766428455051.png)
<!-- slide -->
![PPO Winning Metrics - PPO winning with negative bill and high comfort](C:/Users/quanp/.gemini/antigravity/brain/c6041e0b-5d1e-4f60-abf9-0983a187a48b/ppo_winning_metrics_1766428495644.png)
<!-- slide -->
![PPO Devices View - Device status under PPO control](C:/Users/quanp/.gemini/antigravity/brain/c6041e0b-5d1e-4f60-abf9-0983a187a48b/ppo_devices_view_1766428673370.png)
````

### Video Recording:

![Simulation Recording](C:/Users/quanp/.gemini/antigravity/brain/c6041e0b-5d1e-4f60-abf9-0983a187a48b/ppo_simulation_view_1766428435240.webp)

---

## üéì K·∫øt Lu·∫≠n & Recommendations

### T·∫°i sao PPO > Hybrid?

1. **PPO t·ªëi ∆∞u to√†n c·ª•c** - H·ªçc ƒë∆∞·ª£c strategy end-to-end t·ª´ reward signal
2. **Hybrid b·ªã gi·ªõi h·∫°n b·ªüi rules c·ª©ng** - Rules c√≥ th·ªÉ conflict v·ªõi optimal policy
3. **PPO t·∫≠n d·ª•ng gi√° ƒëi·ªán t·ªët h∆°n** - Kh√¥ng b·ªã r√†ng bu·ªôc b·ªüi "off-peak = r·∫ª"
4. **PPO qu·∫£n l√Ω comfort proactively** - Pre-cool thay v√¨ reactive cooling

### Recommendations ƒë·ªÉ c·∫£i thi·ªán Hybrid:

1. **Relaxed rules**: Thay `a[4] = 1.0` b·∫±ng `a[4] = max(a[4], 0.5)` 
2. **Dynamic thresholds**: D√πng SOC/price thay v√¨ gi·ªù c·ªë ƒë·ªãnh
3. **Reward shaping thay v√¨ override**: Th√™m bonus v√†o reward cho safe behaviors
4. **Remove conflicting rules**: B·ªè rule AC off khi kh√¥ng c√≥ ai, ƒë·ªÉ PPO t·ª± h·ªçc

---

## üìÅ Files Analyzed

| File | Purpose |
|------|---------|
| [smart_home_env.py](file:///c:/Users/quanp/PycharmProjects/SmartHomeEnv/backend/smart_home_env.py) | Environment + Reward Function |
| [rl_ppo.py](file:///c:/Users/quanp/PycharmProjects/SmartHomeEnv/backend/rl_ppo.py) | Pure PPO Training |
| [rl_ppo_hybrid_new.py](file:///c:/Users/quanp/PycharmProjects/SmartHomeEnv/backend/rl_ppo_hybrid_new.py) | Hybrid Agent + Rules |
| [device_config.py](file:///c:/Users/quanp/PycharmProjects/SmartHomeEnv/backend/device_config.py) | Device & Occupancy Config |
| [main.py](file:///c:/Users/quanp/PycharmProjects/SmartHomeEnv/backend/main.py) | FastAPI Simulation Server |
