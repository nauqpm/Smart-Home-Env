"""
Gym environment for Smart Home HEMS with hybrid scheme:
- agent controls shiftable loads (SU and SI)
- adjustable loads + buy/sell are optimized online using one-step MILP (pulp) or heuristic fallback
Usage:
    from smart_home_env import SmartHomeEnv
"""
import numpy as np
import gymnasium as gym
from gymnasium import spaces
from human_behavior import HumanBehavior # ƒê·∫£m b·∫£o import file human_behavior.py M·ªöI (File 2)

try:
    import pulp
except Exception:
    pulp = None
    print("WARNING: pulp not installed. _solve_one_step will use heuristic fallback.")

# === L·∫§Y DEVICE_POWER_MAP T·ª™ run_episode_plot.py ===
# T·ªët h∆°n l√† n√™n ƒë·ªãnh nghƒ©a n√≥ ·ªü ƒë√¢y ho·∫∑c trong 1 file config chung
DEVICE_POWER_MAP = {
    "lights": 0.1, "fridge": 0.2, "tv": 0.15, "ac": 1.5, "heater": 1.0,
    "washing_machine": 0.5, "dishwasher": 0.8, "laptop": 0.08, "ev_charger": 3.3
}
# ====================================================

class SmartHomeEnv(gym.Env):
    metadata = {'render.modes': ['human']}

    def __init__(self, price_profile, pv_profile, config, forecast_horizon=3):
        super().__init__()
        self.price = np.array(price_profile)
        self.pv = np.array(pv_profile)
        self.cfg = config
        self.T = len(self.price)
        self.forecast_horizon = forecast_horizon

        # self.behavior S·∫º ƒê∆Ø·ª¢C SET T·ª™ B√äN NGO√ÄI (qua set_month_behavior ho·∫∑c .behavior)
        self.behavior = None

        # === M√î PH·ªéNG TH·ªúI TI·∫æT ===
        self.weather_states = ["sunny", "mild", "cloudy", "rainy", "stormy"]
        self.weather_factors = {
            "sunny": 1.0, "mild": 0.8, "cloudy": 0.5,
            "rainy": 0.3, "stormy": 0.1
        }
        # Ma tr·∫≠n chuy·ªÉn Markov cho th·ªùi ti·∫øt
        self.weather_transition = {
            "sunny": [0.6, 0.25, 0.1, 0.04, 0.01],
            "mild": [0.2, 0.5, 0.2, 0.08, 0.02],
            "cloudy": [0.1, 0.2, 0.4, 0.2, 0.1],
            "rainy": [0.05, 0.1, 0.25, 0.4, 0.2],
            "stormy": [0.02, 0.08, 0.2, 0.3, 0.4]
        }


        # Th√¥ng s·ªë chung
        self.time_step = 1.0  # 1h m·ªói b∆∞·ªõc
        self.total_cost = 0.0
        self.total_energy_bought = 0.0

        # C·∫•u h√¨nh t·∫£i
        self.N_ad = len(config.get('adjustable', []))
        self.N_su = len(config.get('shiftable_su', []))
        self.N_si = len(config.get('shiftable_si', []))

        # Kh√¥ng gian quan s√°t v√† h√†nh ƒë·ªông
        # === S·ª¨A L·ªñI: obs_len ph·∫£i kh·ªõp v·ªõi _get_obs ===
        # _get_obs tr·∫£ v·ªÅ: 4 + 2*forecast_horizon + N_si + N_su
        obs_len = 4 + 2 * self.forecast_horizon + self.N_si + self.N_su
        self.observation_space = spaces.Box(low=-1e6, high=1e6, shape=(obs_len,), dtype=np.float32)
        self.action_space = spaces.MultiBinary(self.N_su + self.N_si)

        # Kh√¥ng g·ªçi reset() ·ªü ƒë√¢y, h√£y ƒë·ªÉ script b√™n ngo√†i g·ªçi
        # self.reset()

    def set_month_behavior(self, month_behavior):
        """
        N·∫°p h√†nh vi nhi·ªÅu ng√†y (multi-day) t·ª´ HumanBehavior
        month_behavior: dict[day_index] = daily_behavior
        """
        self.month_behavior = month_behavior
        self.current_day = 0
        self.current_behavior = month_behavior[self.current_day]
        print(f"üìÖ M√¥ ph·ªèng b·∫Øt ƒë·∫ßu: Ng√†y {self.current_day}, lo·∫°i ng√†y = {self.current_behavior['event_type']}")

    def _update_behavior_for_new_day(self):
        """Chuy·ªÉn sang ng√†y ti·∫øp theo v√† c·∫≠p nh·∫≠t h√†nh vi"""
        if hasattr(self, "month_behavior"):
            self.current_day = (self.current_day + 1) % len(self.month_behavior)
            self.current_behavior = self.month_behavior[self.current_day]
            print(f"üìÖ Chuy·ªÉn sang ng√†y {self.current_day}, lo·∫°i ng√†y = {self.current_behavior['event_type']}")


    def reset(self):
        self.t = 0
        bat = self.cfg.get('battery', {})
        self.SOC = bat.get('soc0', 0.5)
        self.Ot_si = [0] * self.N_si
        self.su_started = [False] * self.N_su
        self.su_remaining = [self.cfg['shiftable_su'][i]['L'] for i in range(self.N_su)]
        self.total_cost = 0.0
        self.total_energy_bought = 0.0
        self.current_weather = "mild"
        self.weather_series = []

        # === S·ª¨A LOGIC RESET ===
        # KH√îNG ghi ƒë√® self.behavior n·∫øu n√≥ ƒë√£ ƒë∆∞·ª£c set (v√≠ d·ª•: qua set_month_behavior)
        if hasattr(self, "current_behavior"):
            # Ch·∫ø ƒë·ªô Multi-day
            self.behavior = self.current_behavior
        elif not hasattr(self, 'behavior') or self.behavior is None:
            # Ch·∫ø ƒë·ªô Single-day (ho·∫∑c fallback)
            # T·∫°o behavior 1 ng√†y v√† b·ªçc n√≥ l·∫°i ƒë·ªÉ t∆∞∆°ng th√≠ch
            print("C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y 'current_behavior', t·∫°o behavior 1 ng√†y (fallback).")
            hb_single = HumanBehavior(T=self.T, weather=self.current_weather)
            behavior_data = hb_single.generate_daily_behavior(sample_device_states=True)
            # G√°n behavior_data (l√† dict) tr·ª±c ti·∫øp
            self.behavior = behavior_data
        # N·∫øu self.behavior ƒë√£ ƒë∆∞·ª£c set (v√≠ d·ª•: BehaviorWrapper), c·ª© ƒë·ªÉ y√™n.
        # =======================

        for t in range(self.T):
            probs = self.weather_transition[self.current_weather]
            self.current_weather = np.random.choice(self.weather_states, p=probs)
            self.weather_series.append(self.current_weather)

        # L·∫•y obs v√† ƒë·∫£m b·∫£o n√≥ ƒë√∫ng shape
        obs = self._get_obs()
        if obs.shape != self.observation_space.shape:
             raise ValueError(f"L·ªói Shape: observation_space shape {self.observation_space.shape} "
                              f"nh∆∞ng _get_obs() tr·∫£ v·ªÅ shape {obs.shape}")
        return obs

    def _get_obs(self):
        # Observation bao g·ªìm d·ª± b√°o ng·∫Øn h·∫°n
        t_norm = self.t / max(1, self.T - 1)
        rho = self.price[self.t]
        pv_now = self.pv[self.t]

        # d·ª± b√°o PV v√† gi√° (theo horizon)
        forecast_prices = self.price[self.t:min(self.t + self.forecast_horizon, self.T)]
        forecast_pv = self.pv[self.t:min(self.t + self.forecast_horizon, self.T)]

        # Th√™m padding n·∫øu d·ª± b√°o ng·∫Øn h∆°n horizon
        if len(forecast_prices) < self.forecast_horizon:
            forecast_prices = np.pad(forecast_prices, (0, self.forecast_horizon - len(forecast_prices)), 'edge')
        if len(forecast_pv) < self.forecast_horizon:
            forecast_pv = np.pad(forecast_pv, (0, self.forecast_horizon - len(forecast_pv)), 'edge')

        obs = [t_norm, rho, pv_now, self.SOC]
        obs += forecast_prices.tolist() + forecast_pv.tolist()
        obs += self.Ot_si
        obs += [1.0 if s else 0.0 for s in self.su_started]
        return np.array(obs, dtype=np.float32)

    def step(self, action):
        action = np.array(action).astype(int)
        act_su = action[:self.N_su].tolist() if self.N_su > 0 else []
        act_si = action[self.N_su:].tolist() if self.N_si > 0 else []

        # ===== 1. T√çNH TO√ÅN T·∫¢I =====

        # --- 1a. T·∫£i ƒëi·ªÅu khi·ªÉn b·ªüi Agent ---
        P_su_t = sum(su["rate"] for i, su in enumerate(self.cfg["shiftable_su"])
                     if self.t >= su["t_s"] and self.t <= su["t_f"] and act_su[i] == 1)
        P_si_t = sum(si["rate"] for i, si in enumerate(self.cfg["shiftable_si"])
                     if self.t >= si["t_s"] and self.t <= si["t_f"] and act_si[i] == 1)

        # --- 1b. T·∫£i C·ªë ƒë·ªãnh v√† ƒêi·ªÅu ch·ªânh (Adjustable) ---
        P_cr_t = self.cfg.get("critical", [0.0] * self.T)[self.t]
        P_ad_t = sum(ad["P_com"] for ad in self.cfg.get("adjustable", [])) # Gi·∫£ ƒë·ªãnh P_com

        # --- 1c. T·∫£i c·ªßa Con ng∆∞·ªùi (Human Behavior) ---
        # Logic n√†y s·∫Ω thay th·∫ø kh·ªëi (142-161) c≈©
        P_human_t = 0.0
        device_states_t = {} # ƒê·ªÉ l∆∞u tr·∫°ng th√°i cho info

        if isinstance(self.behavior, dict):
            # Ch·∫ø ƒë·ªô Multi-day (behavior l√† dict t·ª´ HumanBehavior M·ªöI)
            device_states = self.behavior.get("device_states")
            if device_states:
                for device_name, power in DEVICE_POWER_MAP.items():
                    # L·∫•y tr·∫°ng th√°i ON/OFF c·ªßa thi·∫øt b·ªã t·∫°i gi·ªù t
                    is_on = device_states.get(device_name, [False]*self.T)[self.t]
                    device_states_t[device_name] = is_on
                    if is_on:
                        # KI·ªÇM TRA XUNG ƒê·ªòT: Kh√¥ng t√≠nh t·∫£i n·∫øu agent ƒëang ƒëi·ªÅu khi·ªÉn n√≥
                        # (Gi·∫£ ƒë·ªãnh: agent "th·∫Øng" con ng∆∞·ªùi)
                        is_agent_controlled = False
                        if device_name == "washing_machine": # T√™n n√†y ph·∫£i kh·ªõp v·ªõi DEVICE_POWER_MAP
                             is_agent_controlled = True # Gi·∫£ s·ª≠ SU[0] l√† washing_machine
                        if device_name == "dishwasher":
                             is_agent_controlled = True # Gi·∫£ s·ª≠ SU[1] l√† dishwasher
                        if device_name == "ev_charger":
                             is_agent_controlled = True # Gi·∫£ s·ª≠ SI[0] l√† ev_charger

                        if not is_agent_controlled:
                            P_human_t += power

        elif hasattr(self.behavior, 'device_usage'):
            # Ch·∫ø ƒë·ªô Single-day (d√πng BehaviorWrapper)
            # (Logic n√†y gi·ªëng h·ªát kh·ªëi 142-161 c≈©, nh∆∞ng truy c·∫≠p ƒë√∫ng)
            occ_factor = self.behavior.occupancy[self.t]
            device_profile = self.behavior.device_usage # ƒê√¢y l√† device_probs

            if occ_factor > 0.7 and isinstance(device_profile, dict):
                # Ki·ªÉm tra key t·ªìn t·∫°i tr∆∞·ªõc khi truy c·∫≠p
                if "tv" in device_profile and device_profile["tv"][self.t] > 0.5:
                    P_human_t += DEVICE_POWER_MAP["tv"]
                if "ac" in device_profile and device_profile["ac"][self.t] > 0.5:
                    P_human_t += DEVICE_POWER_MAP["ac"]
                if "laptop" in device_profile and device_profile["laptop"][self.t] > 0.5:
                    P_human_t += DEVICE_POWER_MAP["laptop"]
                if "heater" in device_profile and device_profile["heater"][self.t] > 0.5:
                    P_human_t += DEVICE_POWER_MAP["heater"]

        # --- 1d. T·∫£i T·ªïng c·ªông ---
        P_load = P_cr_t + P_ad_t + P_su_t + P_si_t + P_human_t


        # === T√ÅC ƒê·ªòNG C·ª¶A TH·ªúI TI·∫æT L√äN PV ===
        weather = self.weather_series[self.t]
        weather_factor = self.weather_factors[weather]
        P_pv = self.pv[self.t] * weather_factor

        # ===== 2. X·ª¨ L√ù PIN =====
        bat = self.cfg.get("battery", {})
        soc_min = bat.get("soc_min", 0.1)
        soc_max = bat.get("soc_max", 0.9)
        eta_ch = bat.get("eta_ch", 0.95)
        eta_dis = bat.get("eta_dis", 0.95)

        P_ch, P_dis = 0.0, 0.0
        if P_pv >= P_load:
            P_surplus = P_pv - P_load
            if self.SOC < soc_max:
                P_ch = P_surplus
                # === S·ª¨A L·ªñI T√çNH TO√ÅN SOC ===
                # Ph·∫£i chia cho dung l∆∞·ª£ng pin (v√≠ d·ª•: C_bat) ho·∫∑c chu·∫©n h√≥a
                # Gi·∫£ s·ª≠ self.T l√† dung l∆∞·ª£ng pin (C√°ch t√≠nh c≈© c·ªßa b·∫°n)
                # T·ªët h∆°n: Gi·∫£ s·ª≠ pin c√≥ dung l∆∞·ª£ng 10kWh, P_ch t√≠nh b·∫±ng kW
                # C_bat = 10 # kWh
                # self.SOC = min(soc_max, self.SOC + (eta_ch * P_ch * self.time_step) / C_bat)
                # T·∫°m d√πng c√°ch t√≠nh c≈© c·ªßa b·∫°n:
                self.SOC = min(soc_max, self.SOC + eta_ch * P_ch / self.T)
        else:
            P_deficit = P_load - P_pv
            if self.SOC > soc_min:
                P_dis = min(P_deficit, (self.SOC - soc_min) * self.T / eta_dis)
                self.SOC = max(soc_min, self.SOC - P_dis * eta_dis / self.T)

        # ===== 3. C√ÇN B·∫∞NG L∆Ø·ªöI =====
        supply = P_pv + P_dis
        demand = P_load + P_ch
        self.P_grid = max(0, demand - supply)  # ch·ªâ mua ƒëi·ªán

        # ===== 4. REWARD ADVANCED =====
        price = self.price[self.t]
        cost = self.P_grid * price
        self.total_cost += cost
        self.total_energy_bought += self.P_grid * self.time_step

        hour = self.t % 24
        is_night = (hour < 6 or hour >= 18)
        penalty_unmet = -10.0 * max(0, demand - supply - self.P_grid)
        penalty_battery = -0.05 * (abs(P_ch) + abs(P_dis))

        # Reward kh·ªüi t·∫°o
        reward = -cost + penalty_unmet + penalty_battery

        # Logic ban ƒë√™m
        if is_night:
            if self.P_grid > 0:
                reward -= 0.2 * cost  # ph·∫°t th√™m n·∫øu d√πng ƒëi·ªán l∆∞·ªõi
            elif P_dis > 0:
                reward += 0.05 * P_dis  # th∆∞·ªüng nh·∫π n·∫øu d√πng pin

        # Logic n√¢ng cao: SOC, gi·ªù cao ƒëi·ªÉm, t·∫≠n d·ª•ng PV
        if 17 <= hour <= 21:
            reward -= 0.5 * cost  # ph·∫°t gi·ªù cao ƒëi·ªÉm
        if 0.4 <= self.SOC <= 0.8:
            reward += 0.02  # th∆∞·ªüng SOC ·ªïn ƒë·ªãnh
        reward += 0.03 * min(P_pv, P_load)  # th∆∞·ªüng t·∫≠n d·ª•ng PV

        info = {
            "P_pv": P_pv,
            "P_load": P_load,
            "P_ch": P_ch,
            "P_dis": P_dis,
            "P_grid": self.P_grid,
            "SOC": self.SOC,
            "cost": cost,
            "is_night": is_night,
            "weather": weather,
            "weather_factor": weather_factor,
            "P_human": P_human_t,
            "P_agent_su": P_su_t,
            "P_agent_si": P_si_t,
            "device_states": device_states_t
        }

        self.t += 1
        done = (self.t >= self.T)
        if done:
            self._update_behavior_for_new_day()

        obs = self._get_obs() if not done else np.zeros(self.observation_space.shape, dtype=np.float32)
        # ƒê·∫£m b·∫£o obs tr·∫£ v·ªÅ c√≥ shape ch√≠nh x√°c
        if obs.shape != self.observation_space.shape:
            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p done=True v√† tr·∫£ v·ªÅ obs 0
            if done:
                 obs = np.zeros(self.observation_space.shape, dtype=np.float32)
            else:
                raise ValueError(f"L·ªói Shape sau khi step: observation_space shape {self.observation_space.shape} "
                                 f"nh∆∞ng _get_obs() tr·∫£ v·ªÅ shape {obs.shape}")

        return obs, reward, done, info

    def _solve_one_step(self, P_net_without_ad):
        # ... (H√†m n√†y kh√¥ng thay ƒë·ªïi) ...
        rho_b = self.price[self.t]
        if pulp is None or self.N_ad == 0:
            P_ad = []
            for ad in self.cfg.get('adjustable', []):
                P_ad.append(ad['P_com'] if rho_b < np.mean(self.price) else ad['P_min'])
            P_ad = np.array(P_ad)
            P_net = P_net_without_ad + P_ad.sum()
            if P_net >= 0:
                return P_ad.tolist(), float(P_net), 0.0
            else:
                return P_ad.tolist(), 0.0, float(-P_net)

        # build small LP with pulp
        prob = pulp.LpProblem('OneStep', pulp.LpMinimize)
        P_ad_vars = [pulp.LpVariable(f'P_ad_{i}', lowBound=ad['P_min'], upBound=ad['P_max']) for i,ad in enumerate(self.cfg.get('adjustable', []))]
        P_b_var = pulp.LpVariable('P_b', lowBound=0.0)
        P_s_var = pulp.LpVariable('P_s', lowBound=0.0)
        z_b = pulp.LpVariable('z_b', cat='Binary')
        z_s = pulp.LpVariable('z_s', cat='Binary')
        bigM = 1e5
        prob += (P_b_var - P_s_var == P_net_without_ad + pulp.lpSum(P_ad_vars))
        prob += P_b_var <= z_b * bigM
        prob += P_s_var <= z_s * bigM
        prob += z_b + z_s <= 1
        obj = rho_b * P_b_var - (self.cfg.get('beta',0.5)*rho_b) * P_s_var
        for i,ad in enumerate(self.cfg.get('adjustable', [])):
            u = pulp.LpVariable(f'u_{i}', lowBound=0.0)
            prob += u >= ad['P_com'] - P_ad_vars[i]
            prob += u >= P_ad_vars[i] - ad['P_com']
            obj += ad['alpha'] * u
            obj += rho_b * P_ad_vars[i]
        prob += obj
        solver = pulp.PULP_CBC_CMD(msg=False, timeLimit=5)
        prob.solve(solver)
        P_ad = [float(pulp.value(v)) if pulp.value(v) is not None else 0.0 for v in P_ad_vars]
        P_b = float(pulp.value(P_b_var)) if pulp.value(P_b_var) is not None else 0.0
        P_s = float(pulp.value(P_s_var)) if pulp.value(P_s_var) is not None else 0.0
        return P_ad, P_b, P_s

    def get_tiered_price(total_consumption_kwh):
        # ... (H√†m n√†y kh√¥ng thay ƒë·ªïi) ...
        # Gi√° ƒëi·ªán theo b·∫≠c (ƒë·ªìng/kWh)
        tiers = [
            (50, 1984),
            (100, 2050),
            (200, 2380),
            (300, 2998),
            (400, 3350),
            (float('inf'), 3460),
        ]

        # T√≠nh to√°n gi√° trung b√¨nh (theo m·ª©c d√πng t√≠ch l≈©y)
        remaining = total_consumption_kwh
        cost = 0
        last_limit = 0

        for limit, price in tiers:
            usage = min(remaining, limit - last_limit)
            cost += usage * price
            remaining -= usage
            last_limit = limit
            if remaining <= 0:
                break

        avg_price = cost / total_consumption_kwh if total_consumption_kwh > 0 else tiers[0][1]
        return avg_price / 1000  # ƒë·ªïi sang kWh ‚Üí ƒë·ªìng/kWh (n·∫øu c·∫ßn scale)

    def render(self, mode='human'):
        print(f"t={self.t}, total_cost={self.total_cost:.3f}")


if __name__ == "__main__":
    # quick demo
    T = 24
    price = 0.1 + 0.2 * np.random.rand(T)
    pv = np.clip(1.5 * np.sin(np.linspace(0, 3.14, T)) + 0.2*np.random.randn(T), 0, None)
    config = {
        'critical': [0.3]*T,
        'adjustable': [
            {'P_min':0.1, 'P_max':1.5, 'P_com':1.2, 'alpha':0.06},
            {'P_min':0.0, 'P_max':1.2, 'P_com':1.0, 'alpha':0.12}
        ],
        'shiftable_su': [ {'rate':0.5, 'L':2, 't_s':6, 't_f':20}, {'rate':0.6, 'L':1, 't_s':8, 't_f':22} ],
        'shiftable_si': [ {'rate':1.0, 'E':4.0, 't_s':0, 't_f':23} ],
        'beta': 0.5,
        'battery': {'soc0':0.5, 'soc_min':0.1, 'soc_max':0.9},
        "reward_mode": "advanced"
    }
    env = SmartHomeEnv(price, pv, config)

    # === Demo cho Ch·∫ø ƒë·ªô 1 ng√†y (Single-day) ===
    # (ƒê·ªÉ demo multi-day, b·∫°n c·∫ßn ch·∫°y run_episode_plot.py)
    print("--- Ch·∫°y Demo 1 ng√†y (Single-day) ---")
    obs = env.reset() # reset() s·∫Ω t·ª± t·∫°o behavior fallback
    done = False
    while not done:
        action = np.random.randint(0,2, size=env.N_su + env.N_si)
        obs, rew, done, info = env.step(action)
    print("Episode finished, total cost", env.total_cost)